{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Base"]},{"cell_type":"code","execution_count":1,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-09-11T23:06:20.414596Z","iopub.status.busy":"2024-09-11T23:06:20.413578Z","iopub.status.idle":"2024-09-11T23:06:25.500884Z","shell.execute_reply":"2024-09-11T23:06:25.499644Z","shell.execute_reply.started":"2024-09-11T23:06:20.414537Z"},"trusted":true},"outputs":[],"source":["import json\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","from   matplotlib import colors\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-09-11T23:06:25.503935Z","iopub.status.busy":"2024-09-11T23:06:25.503277Z","iopub.status.idle":"2024-09-11T23:06:25.509676Z","shell.execute_reply":"2024-09-11T23:06:25.508563Z","shell.execute_reply.started":"2024-09-11T23:06:25.503877Z"},"trusted":true},"outputs":[],"source":["device  = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"]},{"cell_type":"markdown","metadata":{},"source":["### Helper Functions\n","Defining some helper functions to pad a given grid to 30x30, preprocess the images to one hot vectors and count the number of parameters in our model"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-09-11T23:38:29.064221Z","iopub.status.busy":"2024-09-11T23:38:29.063747Z","iopub.status.idle":"2024-09-11T23:38:29.073171Z","shell.execute_reply":"2024-09-11T23:38:29.071758Z","shell.execute_reply.started":"2024-09-11T23:38:29.064176Z"},"trusted":true},"outputs":[],"source":["def num_params(model):\n","    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n","\n","def pad(grid, pad_value=10):\n","    h, w = len(grid), len(grid[0])\n","    output = torch.full((30, 30), pad_value, dtype=torch.int8)\n","    output[:h, :w] = torch.tensor(grid, dtype=torch.int8)\n","    return output\n","\n","def preprocess(dataset):\n","        ret = F.one_hot(dataset, num_classes=11).permute(0, 3, 1, 2)\n","        return ret.float()"]},{"cell_type":"markdown","metadata":{},"source":["### Visualization\n","Simple function to visualize the grids for the ARC tasks"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-09-11T23:08:18.483032Z","iopub.status.busy":"2024-09-11T23:08:18.482587Z","iopub.status.idle":"2024-09-11T23:08:18.676704Z","shell.execute_reply":"2024-09-11T23:08:18.675088Z","shell.execute_reply.started":"2024-09-11T23:08:18.482975Z"},"trusted":true},"outputs":[{"data":{"image/png":"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","text/plain":["<Figure size 300x100 with 1 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["myColors = colors.ListedColormap(\n","    ['#000000', '#0074D9', '#FF4136', '#2ECC40', '#FFDC00',\n","     '#AAAAAA', '#F012BE', '#FF851B', '#7FDBFF', '#870C25', \"#FFFFFF\"])\n","normalization = colors.Normalize(vmin=0, vmax=10)\n","\n","def visualize(mat, ax, title=\"\"):\n","    ax.imshow(mat, cmap=myColors, norm=normalization)\n","    ax.grid(True, which = 'both',color = 'lightgrey', linewidth = 0.5)\n","    ax.set_yticks([x-0.5 for x in range(1 + len(mat))])\n","    ax.set_xticks([x-0.5 for x in range(1 + len(mat[0]))]) \n","    if len(title) > 0: ax.set_title(title)\n","    ax.set_xticklabels([])\n","    ax.set_yticklabels([])\n","    \n","plt.figure(figsize=(3, 1), dpi=100)\n","plt.imshow([list(range(10+1))], cmap=myColors, norm=normalization)\n","plt.xticks(list(range(10+1)))\n","plt.yticks([])\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["### Load Data "]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2024-09-11T23:50:24.445308Z","iopub.status.busy":"2024-09-11T23:50:24.444835Z","iopub.status.idle":"2024-09-11T23:50:24.949445Z","shell.execute_reply":"2024-09-11T23:50:24.948205Z","shell.execute_reply.started":"2024-09-11T23:50:24.445261Z"},"trusted":true},"outputs":[],"source":["with open(\"../input/arc-prize-2024/arc-agi_training_challenges.json\", 'r') as f:\n","    train_challenges = json.load(f)\n","with open('../input/arc-prize-2024/arc-agi_training_solutions.json', 'r') as f:\n","    train_solutions = json.load(f)\n","with open(\"../input/arc-prize-2024/arc-agi_test_challenges.json\", 'r') as f:\n","    test_challenges = json.load(f)\n","test_ids = list(test_challenges.keys())\n","train_ids = list(train_challenges.keys())"]},{"cell_type":"markdown","metadata":{},"source":["### Model Setup\n","Define Residual, Convolutional, Encoder, Decoder as well as Multi Layer Perceptron layers to be used by our ARCSolver CNN model. "]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2024-09-11T23:15:21.163466Z","iopub.status.busy":"2024-09-11T23:15:21.162492Z","iopub.status.idle":"2024-09-11T23:15:21.177701Z","shell.execute_reply":"2024-09-11T23:15:21.176497Z","shell.execute_reply.started":"2024-09-11T23:15:21.163419Z"},"trusted":true},"outputs":[],"source":["class ResBlock(nn.Module):\n","    def __init__(self, C: int, dropout: float):\n","        super().__init__()\n","        self.relu = nn.ReLU(inplace=True)\n","        self.bnorm1 = nn.BatchNorm2d(C)\n","        self.bnorm2 = nn.BatchNorm2d(C)\n","        self.conv1 = nn.Conv2d(C, C, kernel_size=3, padding=1)\n","        self.conv2 = nn.Conv2d(C, C, kernel_size=3, padding=1)\n","        self.dropout = nn.Dropout(p=dropout)\n","\n","    def forward(self, x):\n","        x = x\n","        r = self.conv1(self.relu(self.bnorm1(x)))\n","        r = self.dropout(r)\n","        r = self.conv2(self.relu(self.bnorm2(r)))\n","        return r + x\n","\n","class ConvBlock(nn.Module):\n","    def __init__(self, mode: str, conv_in: int, conv_out: int, dropout: float):\n","        super().__init__()\n","        self.relu = nn.ReLU()\n","        self.bnorm = nn.BatchNorm2d(conv_out)\n","        if mode==\"down\":\n","            self.conv = nn.Conv2d(conv_in, conv_out, kernel_size=4, stride=2, padding=0)\n","        elif mode==\"up\":\n","            self.conv = nn.ConvTranspose2d(conv_in, conv_out, kernel_size=4, stride=2, padding=0)\n","        elif mode==\"same\":\n","            self.conv = nn.Conv2d(conv_in, conv_out, kernel_size=3, padding=1)\n","        else:\n","            raise ValueError(\"Invalid mode passed in to ConvBlock.\")\n","        self.dropout = nn.Dropout(p=dropout)\n","\n","    def forward(self, z):\n","        x = self.conv(z)\n","        x = self.bnorm(x)\n","        x = self.relu(x)\n","        x = self.dropout(x)\n","        return x\n"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2024-09-11T23:15:26.830381Z","iopub.status.busy":"2024-09-11T23:15:26.829964Z","iopub.status.idle":"2024-09-11T23:15:26.854733Z","shell.execute_reply":"2024-09-11T23:15:26.853651Z","shell.execute_reply.started":"2024-09-11T23:15:26.830342Z"},"trusted":true},"outputs":[],"source":["class Encoder(nn.Module):\n","    def __init__(self, channels=[256, 512, 512], latent_dim=512, dropout=0.1):\n","        super(Encoder, self).__init__()\n","        self.conv1 = ConvBlock(\"down\", 11,  channels[0], dropout)\n","        self.res12 = ResBlock(channels[0], dropout)\n","        self.conv2 = ConvBlock(\"down\", channels[0], channels[1], dropout)\n","        self.res23 = ResBlock(channels[1], dropout)\n","        self.conv3 = ConvBlock(\"down\", channels[1], channels[2], dropout)\n","        self.fc = nn.Linear(channels[2] * 2 * 2, latent_dim)\n","\n","    def forward(self, z):\n","        residuals = [0] * 3\n","        x = preprocess(z)\n","        x = self.conv1(x)\n","        x = self.res12(x)\n","        residuals[0] = x\n","        x = self.conv2(x)\n","        x = self.res23(x)\n","        residuals[1] = x\n","        x = self.conv3(x)\n","        residuals[2] = x\n","        x = x.reshape(x.size(0), -1)\n","        encoded = self.fc(x)\n","        return encoded, residuals\n","    \n","class Decoder(nn.Module):\n","    def __init__(self, channels=[256, 512, 512], latent_dim=512, dropout=0.1):\n","        super(Decoder, self).__init__()\n","        self.channels = channels\n","        self.fc = nn.Linear(latent_dim, channels[-1] * 2 * 2)\n","        self.conv3 = ConvBlock(\"up\", channels[-1]*2, channels[-2], dropout)\n","        self.res32 = ResBlock(channels[-2], dropout)\n","        self.conv2 = ConvBlock(\"up\", channels[-2]*2, channels[-3], dropout)\n","        self.res21 = ResBlock(channels[-3], dropout)\n","        self.conv1 = ConvBlock(\"up\", channels[-3]*2, channels[-3], dropout)\n","        self.conv0 = nn.Conv2d(channels[-3], 11, kernel_size=3, padding=1)\n","\n","    def forward(self, z, residuals):\n","        x = self.fc(z)\n","        x = x.reshape(x.size(0), self.channels[-1], 2, 2)\n","        x = torch.cat((x, residuals[2]), dim=1)\n","        x = self.conv3(x)\n","        x = self.res32(x)\n","        x = torch.cat((x, residuals[1]), dim=1)\n","        x = self.conv2(x)\n","        x = self.res21(x)\n","        x = torch.cat((x, residuals[0]), dim=1)\n","        x = self.conv1(x)\n","        x = self.conv0(x)\n","        return x\n","    \n","   \n","class MultiLayerPerceptron(nn.Module):\n","    def __init__(self, input_size, hidden_size, output_size, dropout=0.1):\n","        super(MultiLayerPerceptron, self).__init__()\n","        self.fc1  = nn.Linear(input_size, hidden_size)\n","        self.bn1  = nn.BatchNorm1d(hidden_size)\n","        self.fc2  = nn.Linear(hidden_size, hidden_size)\n","        self.bn2  = nn.BatchNorm1d(hidden_size)\n","        self.fc3  = nn.Linear(hidden_size, output_size)\n","        self.relu = nn.ReLU()\n","        self.dropout = nn.Dropout(p=dropout)\n","        self.hidden_size = hidden_size\n","        self.output_size = output_size\n","\n","    def forward(self, z):\n","        x = self.relu(self.bn1(self.fc1(z)))\n","        x = self.dropout(x)\n","        x = self.relu(self.bn2(self.fc2(x)))\n","        x = self.dropout(x)\n","        output = self.fc3(x)\n","        return output"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2024-09-11T23:15:31.56311Z","iopub.status.busy":"2024-09-11T23:15:31.562082Z","iopub.status.idle":"2024-09-11T23:15:31.573219Z","shell.execute_reply":"2024-09-11T23:15:31.572157Z","shell.execute_reply.started":"2024-09-11T23:15:31.563051Z"},"trusted":true},"outputs":[],"source":["class ARCSolver(nn.Module):\n","    def __init__(self, channels, latent_dim, hidden_size, dropout=0.1):\n","        super(ARCSolver, self).__init__()\n","        self.encoder = Encoder(channels, latent_dim, dropout)\n","        self.decoder = Decoder(channels, latent_dim, dropout)\n","        self.mlp_key = MultiLayerPerceptron(latent_dim * 6, hidden_size, latent_dim)\n","        self.mlp_map = MultiLayerPerceptron(latent_dim * 2, hidden_size, latent_dim)\n","        self.channels    = channels\n","        self.latent_dim  = latent_dim\n","        self.hidden_size = hidden_size\n","\n","    def forward(self, input, examples):\n","        # calculate key\n","        examples_encoded    = examples.flatten(end_dim=-3)\n","        examples_encoded, _ = self.encoder(examples_encoded)\n","        examples_encoded    = examples_encoded.reshape(2, -1, 3, self.latent_dim).permute(1, 0, 2, 3).flatten(start_dim=1)\n","        key = self.mlp_key(examples_encoded)\n","        # encode input\n","        input_encoded, residuals = self.encoder(input)\n","        # calculate encoded_output\n","        output_encoded = self.mlp_map(torch.concat((input_encoded, key), dim=1))\n","        # decode output\n","        output_decoded = self.decoder(output_encoded, residuals)\n","        return output_decoded"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2024-09-12T00:02:39.289395Z","iopub.status.busy":"2024-09-12T00:02:39.288918Z","iopub.status.idle":"2024-09-12T00:02:39.640354Z","shell.execute_reply":"2024-09-12T00:02:39.639077Z","shell.execute_reply.started":"2024-09-12T00:02:39.289351Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["model 38M\n","encoder size: 13292288\n","decoder size: 21661963\n","mlp_key size: 2100736\n","mlp_map size: 1052160\n"]}],"source":["channels    = [256, 512, 512]\n","latent_dim  = 512\n","hidden_size = 512\n","\n","model = ARCSolver(channels, latent_dim, hidden_size)\n","model_size = num_params(model)\n","print(f\"model {int(model_size/1e6)}M\")\n","print(\"encoder size:\", num_params(model.encoder))\n","print(\"decoder size:\", num_params(model.decoder))\n","print(\"mlp_key size:\", num_params(model.mlp_key))\n","print(\"mlp_map size:\", num_params(model.mlp_map))"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2024-09-12T00:22:32.281252Z","iopub.status.busy":"2024-09-12T00:22:32.280735Z","iopub.status.idle":"2024-09-12T00:22:32.293366Z","shell.execute_reply":"2024-09-12T00:22:32.292087Z","shell.execute_reply.started":"2024-09-12T00:22:32.281203Z"},"trusted":true},"outputs":[],"source":["def model_pred(id_val):\n","    training_data = train_challenges[id_val][\"train\"]\n","    training_data = training_data[:3]\n","    while len(training_data) < 3:\n","        training_data += [training_data[-1]]\n","\n","    input = pad(train_challenges[id_val][\"test\"][0][\"input\"]).unsqueeze(0)\n","    examples = torch.zeros((2, 1, 3, 30, 30), dtype=torch.int64)\n","    for j in range(3):\n","        examples[0, 0, j] = pad(training_data[j][\"input\"])\n","        examples[1, 0, j] = pad(training_data[j][\"output\"])\n","    input = input.long()\n","    examples = examples.long()\n","\n","    output_pred_padded = torch.argmax(model(input, examples)[0], dim=0)\n","    lim_hor = (output_pred_padded[0] < 10).sum()\n","    lim_ver = (output_pred_padded[:, 0] < 10).sum()\n","    output_pred = output_pred_padded[:lim_ver, :lim_hor]\n","    return output_pred\n","\n","def model_pred_final(id_val):\n","    training_data = test_challenges[id_val][\"train\"]\n","    training_data = training_data[:3]\n","    while len(training_data) < 3:\n","        training_data += [training_data[-1]]\n","\n","    input = pad(test_challenges[id_val][\"test\"][0][\"input\"]).unsqueeze(0)\n","    examples = torch.zeros((2, 1, 3, 30, 30), dtype=torch.int64)\n","    for j in range(3):\n","        examples[0, 0, j] = pad(training_data[j][\"input\"])\n","        examples[1, 0, j] = pad(training_data[j][\"output\"])\n","    input = input.long()\n","    examples = examples.long()\n","\n","    output_pred_padded = torch.argmax(model(input, examples)[0], dim=0)\n","    lim_hor = (output_pred_padded[0] < 10).sum()\n","    lim_ver = (output_pred_padded[:, 0] < 10).sum()\n","    output_pred = output_pred_padded[:lim_ver, :lim_hor]\n","    return output_pred"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2024-09-12T00:18:24.483998Z","iopub.status.busy":"2024-09-12T00:18:24.483065Z","iopub.status.idle":"2024-09-12T00:18:24.617304Z","shell.execute_reply":"2024-09-12T00:18:24.616141Z","shell.execute_reply.started":"2024-09-12T00:18:24.483952Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["<All keys matched successfully>\n"]}],"source":["print(model.load_state_dict(torch.load(\"../input/arc-prize-2024/model_params.pth\", map_location=device, weights_only=False)))\n","model.eval()\n","model.to(device);"]},{"cell_type":"markdown","metadata":{},"source":["### Creating our Submission"]},{"cell_type":"code","execution_count":36,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Submission created successfully!\n"]}],"source":["submission = {}\n","for key, task in test_challenges.items():\n","    output_pred = model_pred_final(key).cpu().numpy()\n","    submission[key] = [{'attempt_1': output_pred.tolist(), 'attempt_2': output_pred.tolist()}]\n","\n","with open('submission.json', 'w') as fp:\n","    json.dump(submission, fp)\n","\n","print(\"Submission created successfully!\")"]},{"cell_type":"code","execution_count":32,"metadata":{},"outputs":[],"source":["def score_submission():\n","    with open('../input/arc-prize-2024/arc-agi_evaluation_solutions.json', 'r') as sol_file:\n","        solutions = json.load(sol_file)\n","    \n","    with open('submission.json', 'r') as sub_file:\n","        submission = json.load(sub_file)\n","    \n","    overall_score = 0\n","\n","    for task in solutions:\n","        score = 0\n","        for i, answer in enumerate(solutions[task]):\n","            attempt1_correct = submission[task][i]['attempt_1'] == answer\n","            attempt2_correct = submission[task][i]['attempt_2'] == answer\n","            score += int(attempt1_correct or attempt2_correct)\n","\n","        score /= len(solutions[task])\n","\n","        overall_score += score\n","    \n","\n","    print(overall_score)"]},{"cell_type":"code","execution_count":34,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["0.0\n"]},{"data":{"text/plain":["'\\nmy ans\\n\"00576224\": \\n[{\"attempt_1\": [[3, 2, 8, 3], [7, 8, 8, 7], [7, 8, 8, 8], [3, 2, 7, 8]], \"attempt_2\": [[3, 2, 8, 3], [7, 8, 8, 7], [7, 8, 8, 8], [3, 2, 7, 8]]}]\\n\\nexpected ans\\n{\"00576224\": [[[3, 2, 3, 2, 3, 2], [7, 8, 7, 8, 7, 8], [2, 3, 2, 3, 2, 3], [8, 7, 8, 7, 8, 7], [3, 2, 3, 2, 3, 2], [7, 8, 7, 8, 7, 8]]],\\n'"]},"execution_count":34,"metadata":{},"output_type":"execute_result"}],"source":["score_submission()\n","\n","'''\n","my ans\n","\"00576224\": \n","[{\"attempt_1\": [[3, 2, 8, 3], [7, 8, 8, 7], [7, 8, 8, 8], [3, 2, 7, 8]], \"attempt_2\": [[3, 2, 8, 3], [7, 8, 8, 7], [7, 8, 8, 8], [3, 2, 7, 8]]}]\n","\n","expected ans\n","{\"00576224\": [[[3, 2, 3, 2, 3, 2], [7, 8, 7, 8, 7, 8], [2, 3, 2, 3, 2, 3], [8, 7, 8, 7, 8, 7], [3, 2, 3, 2, 3, 2], [7, 8, 7, 8, 7, 8]]],\n","'''\n"]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"databundleVersionId":8951125,"sourceId":67357,"sourceType":"competition"},{"datasetId":5682992,"sourceId":9370433,"sourceType":"datasetVersion"}],"dockerImageVersionId":30761,"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.20"}},"nbformat":4,"nbformat_minor":4}
